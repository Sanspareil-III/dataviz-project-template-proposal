#All XML in Directories (MT) to Single CSV

import pandas as pd
import glob
import os
from lxml import etree
from concurrent.futures import ThreadPoolExecutor, as_completed

def flatten_xml(element, parent_path='', parent_attributes={}):
    base_info = {**parent_attributes, **element.attrib}
    path = parent_path + '/' + element.tag if parent_path else element.tag

    if element.text and element.text.strip():
        base_info[path] = element.text.strip()

    rows = []
    for child in element:
        child_rows = flatten_xml(child, path, base_info)
        rows.extend(child_rows)

    if not element.findall("./*"):
        return [base_info]
    return rows

def process_xml_files_in_folder(folder_path, output_csv_file_path):
    all_data = []
    xml_files = glob.glob(os.path.join(folder_path, '*.pdbxml'))

    if xml_files:
        print(f"Found {len(xml_files)} XML file(s) with .pdbxml extension in '{folder_path}'.")

        for xml_file in xml_files:
            print(f"Processing {xml_file}...")
            tree = etree.parse(xml_file)
            root = tree.getroot()
            flattened_data = flatten_xml(root)
            all_data.extend(flattened_data)

        if all_data:
            df_all = pd.DataFrame(all_data)
            df_all.to_csv(output_csv_file_path, index=False)
            print(f"All data processed into {output_csv_file_path}")
        else:
            print(f"No data to process in '{folder_path}'.")
    else:
        print(f"No .pdbxml files found in '{folder_path}'.")

def process_folders_concurrently(root_folder_path):
    folder_paths = []
    # Walk the directory tree and collect all directories that contain .pdbxml files
    for dirpath, dirnames, filenames in os.walk(root_folder_path):
        if any(fname.endswith('.pdbxml') for fname in filenames):
            folder_paths.append(dirpath)

    # Use ThreadPoolExecutor to process each folder in parallel
    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
        future_to_folder = {executor.submit(process_xml_files_in_folder, folder_path, os.path.join(folder_path, 'consolidated_output.csv')): folder_path for folder_path in folder_paths}
        
        for future in as_completed(future_to_folder):
            folder = future_to_folder[future]
            try:
                future.result()  # You can also use this to catch and handle exceptions
                print(f"Finished processing folder: {folder}")
            except Exception as exc:
                print(f"Error processing folder {folder}: {exc}")

# Example usage - set your root folder path
root_folder_path = r'F:\XML Study'
process_folders_concurrently(root_folder_path)

